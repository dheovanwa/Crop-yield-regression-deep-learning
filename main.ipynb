{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/datasets/patelris/crop-yield-prediction-dataset?select=yield_df.csv\n",
    "\n",
    "Dataset features: \n",
    "- Categorical features: \"Area\", \"Item\", \"Year\"\n",
    "- Continuous features: \"average_rain_fall_mm_per_year\", \"pesticides_tonnes\", \"avg_temp\"\n",
    "- Target: \"hg/ha_yield\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Area</th>\n",
       "      <th>Item</th>\n",
       "      <th>Year</th>\n",
       "      <th>hg/ha_yield</th>\n",
       "      <th>average_rain_fall_mm_per_year</th>\n",
       "      <th>pesticides_tonnes</th>\n",
       "      <th>avg_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Maize</td>\n",
       "      <td>1990</td>\n",
       "      <td>36613</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.00</td>\n",
       "      <td>16.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Potatoes</td>\n",
       "      <td>1990</td>\n",
       "      <td>66667</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.00</td>\n",
       "      <td>16.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Rice, paddy</td>\n",
       "      <td>1990</td>\n",
       "      <td>23333</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.00</td>\n",
       "      <td>16.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Sorghum</td>\n",
       "      <td>1990</td>\n",
       "      <td>12500</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.00</td>\n",
       "      <td>16.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Soybeans</td>\n",
       "      <td>1990</td>\n",
       "      <td>7000</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.00</td>\n",
       "      <td>16.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28237</th>\n",
       "      <td>28237</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Rice, paddy</td>\n",
       "      <td>2013</td>\n",
       "      <td>22581</td>\n",
       "      <td>657.0</td>\n",
       "      <td>2550.07</td>\n",
       "      <td>19.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28238</th>\n",
       "      <td>28238</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Sorghum</td>\n",
       "      <td>2013</td>\n",
       "      <td>3066</td>\n",
       "      <td>657.0</td>\n",
       "      <td>2550.07</td>\n",
       "      <td>19.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28239</th>\n",
       "      <td>28239</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Soybeans</td>\n",
       "      <td>2013</td>\n",
       "      <td>13142</td>\n",
       "      <td>657.0</td>\n",
       "      <td>2550.07</td>\n",
       "      <td>19.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28240</th>\n",
       "      <td>28240</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Sweet potatoes</td>\n",
       "      <td>2013</td>\n",
       "      <td>22222</td>\n",
       "      <td>657.0</td>\n",
       "      <td>2550.07</td>\n",
       "      <td>19.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28241</th>\n",
       "      <td>28241</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>2013</td>\n",
       "      <td>22888</td>\n",
       "      <td>657.0</td>\n",
       "      <td>2550.07</td>\n",
       "      <td>19.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28242 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      Area            Item  Year  hg/ha_yield  \\\n",
       "0               0   Albania           Maize  1990        36613   \n",
       "1               1   Albania        Potatoes  1990        66667   \n",
       "2               2   Albania     Rice, paddy  1990        23333   \n",
       "3               3   Albania         Sorghum  1990        12500   \n",
       "4               4   Albania        Soybeans  1990         7000   \n",
       "...           ...       ...             ...   ...          ...   \n",
       "28237       28237  Zimbabwe     Rice, paddy  2013        22581   \n",
       "28238       28238  Zimbabwe         Sorghum  2013         3066   \n",
       "28239       28239  Zimbabwe        Soybeans  2013        13142   \n",
       "28240       28240  Zimbabwe  Sweet potatoes  2013        22222   \n",
       "28241       28241  Zimbabwe           Wheat  2013        22888   \n",
       "\n",
       "       average_rain_fall_mm_per_year  pesticides_tonnes  avg_temp  \n",
       "0                             1485.0             121.00     16.37  \n",
       "1                             1485.0             121.00     16.37  \n",
       "2                             1485.0             121.00     16.37  \n",
       "3                             1485.0             121.00     16.37  \n",
       "4                             1485.0             121.00     16.37  \n",
       "...                              ...                ...       ...  \n",
       "28237                          657.0            2550.07     19.76  \n",
       "28238                          657.0            2550.07     19.76  \n",
       "28239                          657.0            2550.07     19.76  \n",
       "28240                          657.0            2550.07     19.76  \n",
       "28241                          657.0            2550.07     19.76  \n",
       "\n",
       "[28242 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "cat_cols = [\"Area\", \"Item\"]\n",
    "cont_cols = [\"average_rain_fall_mm_per_year\", \"pesticides_tonnes\", \"avg_temp\"]\n",
    "target_col = \"hg/ha_yield\"\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Item</th>\n",
       "      <th>hg/ha_yield</th>\n",
       "      <th>average_rain_fall_mm_per_year</th>\n",
       "      <th>pesticides_tonnes</th>\n",
       "      <th>avg_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Maize</td>\n",
       "      <td>36613</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Potatoes</td>\n",
       "      <td>66667</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Rice, paddy</td>\n",
       "      <td>23333</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Sorghum</td>\n",
       "      <td>12500</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Soybeans</td>\n",
       "      <td>7000</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area         Item  hg/ha_yield  average_rain_fall_mm_per_year  \\\n",
       "0  Albania        Maize        36613                         1485.0   \n",
       "1  Albania     Potatoes        66667                         1485.0   \n",
       "2  Albania  Rice, paddy        23333                         1485.0   \n",
       "3  Albania      Sorghum        12500                         1485.0   \n",
       "4  Albania     Soybeans         7000                         1485.0   \n",
       "\n",
       "   pesticides_tonnes  avg_temp  \n",
       "0              121.0     16.37  \n",
       "1              121.0     16.37  \n",
       "2              121.0     16.37  \n",
       "3              121.0     16.37  \n",
       "4              121.0     16.37  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns that has no meaning\n",
    "df.drop(columns=['Unnamed: 0', 'Year'], axis='columns',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area                             0\n",
       "Item                             0\n",
       "hg/ha_yield                      0\n",
       "average_rain_fall_mm_per_year    0\n",
       "pesticides_tonnes                0\n",
       "avg_temp                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=766)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_encoder = ce.OneHotEncoder(\n",
    "    cols='Item',\n",
    "    handle_unknown='return_nan',\n",
    "    return_df=True,\n",
    "    use_cat_names=True\n",
    ")\n",
    "X_train = item_encoder.fit_transform(X_train)\n",
    "X_test = item_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Item_Potatoes</th>\n",
       "      <th>Item_Wheat</th>\n",
       "      <th>Item_Plantains and others</th>\n",
       "      <th>Item_Yams</th>\n",
       "      <th>Item_Maize</th>\n",
       "      <th>Item_Cassava</th>\n",
       "      <th>Item_Sorghum</th>\n",
       "      <th>Item_Sweet potatoes</th>\n",
       "      <th>Item_Rice, paddy</th>\n",
       "      <th>Item_Soybeans</th>\n",
       "      <th>average_rain_fall_mm_per_year</th>\n",
       "      <th>pesticides_tonnes</th>\n",
       "      <th>avg_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21434</th>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>6889.26</td>\n",
       "      <td>27.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25470</th>\n",
       "      <td>Spain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>40727.00</td>\n",
       "      <td>12.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>Australia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>23899.00</td>\n",
       "      <td>17.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17463</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>6344.00</td>\n",
       "      <td>16.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16724</th>\n",
       "      <td>Japan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>70262.54</td>\n",
       "      <td>13.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1761.0</td>\n",
       "      <td>118930.56</td>\n",
       "      <td>24.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1761.0</td>\n",
       "      <td>367778.00</td>\n",
       "      <td>27.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26253</th>\n",
       "      <td>Tajikistan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>247.90</td>\n",
       "      <td>8.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23786</th>\n",
       "      <td>Qatar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>27.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12273</th>\n",
       "      <td>India</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>44957.52</td>\n",
       "      <td>25.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22593 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Area  Item_Potatoes  Item_Wheat  Item_Plantains and others  \\\n",
       "21434   Nicaragua            1.0         0.0                        0.0   \n",
       "25470       Spain            0.0         1.0                        0.0   \n",
       "945     Australia            1.0         0.0                        0.0   \n",
       "17463       Kenya            0.0         0.0                        1.0   \n",
       "16724       Japan            0.0         0.0                        0.0   \n",
       "...           ...            ...         ...                        ...   \n",
       "3387       Brazil            0.0         0.0                        0.0   \n",
       "4768       Brazil            0.0         0.0                        0.0   \n",
       "26253  Tajikistan            0.0         0.0                        0.0   \n",
       "23786       Qatar            0.0         0.0                        0.0   \n",
       "12273       India            0.0         0.0                        0.0   \n",
       "\n",
       "       Item_Yams  Item_Maize  Item_Cassava  Item_Sorghum  Item_Sweet potatoes  \\\n",
       "21434        0.0         0.0           0.0           0.0                  0.0   \n",
       "25470        0.0         0.0           0.0           0.0                  0.0   \n",
       "945          0.0         0.0           0.0           0.0                  0.0   \n",
       "17463        0.0         0.0           0.0           0.0                  0.0   \n",
       "16724        1.0         0.0           0.0           0.0                  0.0   \n",
       "...          ...         ...           ...           ...                  ...   \n",
       "3387         0.0         0.0           0.0           1.0                  0.0   \n",
       "4768         0.0         0.0           0.0           1.0                  0.0   \n",
       "26253        0.0         1.0           0.0           0.0                  0.0   \n",
       "23786        0.0         1.0           0.0           0.0                  0.0   \n",
       "12273        0.0         0.0           1.0           0.0                  0.0   \n",
       "\n",
       "       Item_Rice, paddy  Item_Soybeans  average_rain_fall_mm_per_year  \\\n",
       "21434               0.0            0.0                         2280.0   \n",
       "25470               0.0            0.0                          636.0   \n",
       "945                 0.0            0.0                          534.0   \n",
       "17463               0.0            0.0                          630.0   \n",
       "16724               0.0            0.0                         1668.0   \n",
       "...                 ...            ...                            ...   \n",
       "3387                0.0            0.0                         1761.0   \n",
       "4768                0.0            0.0                         1761.0   \n",
       "26253               0.0            0.0                          691.0   \n",
       "23786               0.0            0.0                           74.0   \n",
       "12273               0.0            0.0                         1083.0   \n",
       "\n",
       "       pesticides_tonnes  avg_temp  \n",
       "21434            6889.26     27.35  \n",
       "25470           40727.00     12.52  \n",
       "945             23899.00     17.42  \n",
       "17463            6344.00     16.44  \n",
       "16724           70262.54     13.42  \n",
       "...                  ...       ...  \n",
       "3387           118930.56     24.78  \n",
       "4768           367778.00     27.71  \n",
       "26253             247.90      8.69  \n",
       "23786              68.00     27.92  \n",
       "12273           44957.52     25.35  \n",
       "\n",
       "[22593 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_encoder = ce.BaseNEncoder(\n",
    "    cols='Area',\n",
    "    base=3,\n",
    "    handle_unknown='return_nan',\n",
    "    return_df=True,\n",
    ")\n",
    "X_train = area_encoder.fit_transform(X_train)\n",
    "X_test = area_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area_0</th>\n",
       "      <th>Area_1</th>\n",
       "      <th>Area_2</th>\n",
       "      <th>Area_3</th>\n",
       "      <th>Area_4</th>\n",
       "      <th>Item_Potatoes</th>\n",
       "      <th>Item_Wheat</th>\n",
       "      <th>Item_Plantains and others</th>\n",
       "      <th>Item_Yams</th>\n",
       "      <th>Item_Maize</th>\n",
       "      <th>Item_Cassava</th>\n",
       "      <th>Item_Sorghum</th>\n",
       "      <th>Item_Sweet potatoes</th>\n",
       "      <th>Item_Rice, paddy</th>\n",
       "      <th>Item_Soybeans</th>\n",
       "      <th>average_rain_fall_mm_per_year</th>\n",
       "      <th>pesticides_tonnes</th>\n",
       "      <th>avg_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21434</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>6889.26</td>\n",
       "      <td>27.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25470</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>40727.00</td>\n",
       "      <td>12.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>23899.00</td>\n",
       "      <td>17.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>6344.00</td>\n",
       "      <td>16.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16724</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>70262.54</td>\n",
       "      <td>13.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1761.0</td>\n",
       "      <td>118930.56</td>\n",
       "      <td>24.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1761.0</td>\n",
       "      <td>367778.00</td>\n",
       "      <td>27.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26253</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>247.90</td>\n",
       "      <td>8.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23786</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>27.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>44957.52</td>\n",
       "      <td>25.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22593 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area_0  Area_1  Area_2  Area_3  Area_4  Item_Potatoes  Item_Wheat  \\\n",
       "21434     0.0     0.0     0.0     0.0     1.0            1.0         0.0   \n",
       "25470     0.0     0.0     0.0     0.0     2.0            0.0         1.0   \n",
       "945       0.0     0.0     0.0     1.0     0.0            1.0         0.0   \n",
       "17463     0.0     0.0     0.0     1.0     1.0            0.0         0.0   \n",
       "16724     0.0     0.0     0.0     1.0     2.0            0.0         0.0   \n",
       "...       ...     ...     ...     ...     ...            ...         ...   \n",
       "3387      0.0     0.0     2.0     1.0     0.0            0.0         0.0   \n",
       "4768      0.0     0.0     2.0     1.0     0.0            0.0         0.0   \n",
       "26253     0.0     2.0     0.0     1.0     2.0            0.0         0.0   \n",
       "23786     1.0     0.0     2.0     0.0     1.0            0.0         0.0   \n",
       "12273     0.0     0.0     1.0     1.0     1.0            0.0         0.0   \n",
       "\n",
       "       Item_Plantains and others  Item_Yams  Item_Maize  Item_Cassava  \\\n",
       "21434                        0.0        0.0         0.0           0.0   \n",
       "25470                        0.0        0.0         0.0           0.0   \n",
       "945                          0.0        0.0         0.0           0.0   \n",
       "17463                        1.0        0.0         0.0           0.0   \n",
       "16724                        0.0        1.0         0.0           0.0   \n",
       "...                          ...        ...         ...           ...   \n",
       "3387                         0.0        0.0         0.0           0.0   \n",
       "4768                         0.0        0.0         0.0           0.0   \n",
       "26253                        0.0        0.0         1.0           0.0   \n",
       "23786                        0.0        0.0         1.0           0.0   \n",
       "12273                        0.0        0.0         0.0           1.0   \n",
       "\n",
       "       Item_Sorghum  Item_Sweet potatoes  Item_Rice, paddy  Item_Soybeans  \\\n",
       "21434           0.0                  0.0               0.0            0.0   \n",
       "25470           0.0                  0.0               0.0            0.0   \n",
       "945             0.0                  0.0               0.0            0.0   \n",
       "17463           0.0                  0.0               0.0            0.0   \n",
       "16724           0.0                  0.0               0.0            0.0   \n",
       "...             ...                  ...               ...            ...   \n",
       "3387            1.0                  0.0               0.0            0.0   \n",
       "4768            1.0                  0.0               0.0            0.0   \n",
       "26253           0.0                  0.0               0.0            0.0   \n",
       "23786           0.0                  0.0               0.0            0.0   \n",
       "12273           0.0                  0.0               0.0            0.0   \n",
       "\n",
       "       average_rain_fall_mm_per_year  pesticides_tonnes  avg_temp  \n",
       "21434                         2280.0            6889.26     27.35  \n",
       "25470                          636.0           40727.00     12.52  \n",
       "945                            534.0           23899.00     17.42  \n",
       "17463                          630.0            6344.00     16.44  \n",
       "16724                         1668.0           70262.54     13.42  \n",
       "...                              ...                ...       ...  \n",
       "3387                          1761.0          118930.56     24.78  \n",
       "4768                          1761.0          367778.00     27.71  \n",
       "26253                          691.0             247.90      8.69  \n",
       "23786                           74.0              68.00     27.92  \n",
       "12273                         1083.0           44957.52     25.35  \n",
       "\n",
       "[22593 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22593, 18)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area_0</th>\n",
       "      <th>Area_1</th>\n",
       "      <th>Area_2</th>\n",
       "      <th>Area_3</th>\n",
       "      <th>Area_4</th>\n",
       "      <th>Item_Potatoes</th>\n",
       "      <th>Item_Wheat</th>\n",
       "      <th>Item_Plantains and others</th>\n",
       "      <th>Item_Yams</th>\n",
       "      <th>Item_Maize</th>\n",
       "      <th>Item_Cassava</th>\n",
       "      <th>Item_Sorghum</th>\n",
       "      <th>Item_Sweet potatoes</th>\n",
       "      <th>Item_Rice, paddy</th>\n",
       "      <th>Item_Soybeans</th>\n",
       "      <th>average_rain_fall_mm_per_year</th>\n",
       "      <th>pesticides_tonnes</th>\n",
       "      <th>avg_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Area_0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177355</td>\n",
       "      <td>-0.119036</td>\n",
       "      <td>-0.009138</td>\n",
       "      <td>-0.040623</td>\n",
       "      <td>0.052354</td>\n",
       "      <td>0.071782</td>\n",
       "      <td>-0.017358</td>\n",
       "      <td>-0.009495</td>\n",
       "      <td>0.023937</td>\n",
       "      <td>-0.042775</td>\n",
       "      <td>-0.007638</td>\n",
       "      <td>-0.047050</td>\n",
       "      <td>-0.032368</td>\n",
       "      <td>-0.030519</td>\n",
       "      <td>-0.187975</td>\n",
       "      <td>-0.160156</td>\n",
       "      <td>-0.102554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area_1</th>\n",
       "      <td>-0.177355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061769</td>\n",
       "      <td>0.029130</td>\n",
       "      <td>0.113405</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.070041</td>\n",
       "      <td>-0.024156</td>\n",
       "      <td>0.024535</td>\n",
       "      <td>-0.004848</td>\n",
       "      <td>0.006347</td>\n",
       "      <td>-0.035362</td>\n",
       "      <td>-0.024906</td>\n",
       "      <td>-0.045891</td>\n",
       "      <td>0.074217</td>\n",
       "      <td>-0.277388</td>\n",
       "      <td>-0.137627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area_2</th>\n",
       "      <td>-0.119036</td>\n",
       "      <td>-0.061769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.126279</td>\n",
       "      <td>-0.157695</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>-0.012391</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.044973</td>\n",
       "      <td>-0.006985</td>\n",
       "      <td>0.055197</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>-0.014972</td>\n",
       "      <td>-0.027011</td>\n",
       "      <td>-0.005271</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.273069</td>\n",
       "      <td>0.171113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area_3</th>\n",
       "      <td>-0.009138</td>\n",
       "      <td>0.029130</td>\n",
       "      <td>-0.126279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.044654</td>\n",
       "      <td>0.024766</td>\n",
       "      <td>-0.016493</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>0.056043</td>\n",
       "      <td>-0.026536</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>-0.019050</td>\n",
       "      <td>-0.012830</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>-0.020590</td>\n",
       "      <td>0.174662</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.109561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area_4</th>\n",
       "      <td>-0.040623</td>\n",
       "      <td>0.113405</td>\n",
       "      <td>-0.157695</td>\n",
       "      <td>-0.044654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>-0.041465</td>\n",
       "      <td>0.022875</td>\n",
       "      <td>-0.102920</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>-0.028174</td>\n",
       "      <td>-0.004369</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>-0.233038</td>\n",
       "      <td>-0.236458</td>\n",
       "      <td>-0.257576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Potatoes</th>\n",
       "      <td>0.052354</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>0.024766</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.168337</td>\n",
       "      <td>-0.060119</td>\n",
       "      <td>-0.074880</td>\n",
       "      <td>-0.174613</td>\n",
       "      <td>-0.118700</td>\n",
       "      <td>-0.146874</td>\n",
       "      <td>-0.141034</td>\n",
       "      <td>-0.155281</td>\n",
       "      <td>-0.151723</td>\n",
       "      <td>-0.053614</td>\n",
       "      <td>-0.034586</td>\n",
       "      <td>-0.098620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Wheat</th>\n",
       "      <td>0.071782</td>\n",
       "      <td>0.030191</td>\n",
       "      <td>-0.012391</td>\n",
       "      <td>-0.016493</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>-0.168337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.056775</td>\n",
       "      <td>-0.070714</td>\n",
       "      <td>-0.164899</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>-0.138703</td>\n",
       "      <td>-0.133188</td>\n",
       "      <td>-0.146643</td>\n",
       "      <td>-0.143283</td>\n",
       "      <td>-0.110764</td>\n",
       "      <td>-0.012642</td>\n",
       "      <td>-0.156473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Plantains and others</th>\n",
       "      <td>-0.017358</td>\n",
       "      <td>0.070041</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>-0.060119</td>\n",
       "      <td>-0.056775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025255</td>\n",
       "      <td>-0.058891</td>\n",
       "      <td>-0.040034</td>\n",
       "      <td>-0.049536</td>\n",
       "      <td>-0.047567</td>\n",
       "      <td>-0.052372</td>\n",
       "      <td>-0.051172</td>\n",
       "      <td>0.140193</td>\n",
       "      <td>-0.070127</td>\n",
       "      <td>0.085172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Yams</th>\n",
       "      <td>-0.009495</td>\n",
       "      <td>-0.024156</td>\n",
       "      <td>0.044973</td>\n",
       "      <td>0.056043</td>\n",
       "      <td>-0.041465</td>\n",
       "      <td>-0.074880</td>\n",
       "      <td>-0.070714</td>\n",
       "      <td>-0.025255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.073351</td>\n",
       "      <td>-0.049863</td>\n",
       "      <td>-0.061698</td>\n",
       "      <td>-0.059245</td>\n",
       "      <td>-0.065230</td>\n",
       "      <td>-0.063736</td>\n",
       "      <td>0.124455</td>\n",
       "      <td>0.107397</td>\n",
       "      <td>0.062092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Maize</th>\n",
       "      <td>0.023937</td>\n",
       "      <td>0.024535</td>\n",
       "      <td>-0.006985</td>\n",
       "      <td>-0.026536</td>\n",
       "      <td>0.022875</td>\n",
       "      <td>-0.174613</td>\n",
       "      <td>-0.164899</td>\n",
       "      <td>-0.058891</td>\n",
       "      <td>-0.073351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.116276</td>\n",
       "      <td>-0.143874</td>\n",
       "      <td>-0.138154</td>\n",
       "      <td>-0.152110</td>\n",
       "      <td>-0.148625</td>\n",
       "      <td>-0.032605</td>\n",
       "      <td>-0.026889</td>\n",
       "      <td>-0.043180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Cassava</th>\n",
       "      <td>-0.042775</td>\n",
       "      <td>-0.004848</td>\n",
       "      <td>0.055197</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>-0.102920</td>\n",
       "      <td>-0.118700</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>-0.040034</td>\n",
       "      <td>-0.049863</td>\n",
       "      <td>-0.116276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.097804</td>\n",
       "      <td>-0.093916</td>\n",
       "      <td>-0.103403</td>\n",
       "      <td>-0.101033</td>\n",
       "      <td>0.133368</td>\n",
       "      <td>0.029863</td>\n",
       "      <td>0.163273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Sorghum</th>\n",
       "      <td>-0.007638</td>\n",
       "      <td>0.006347</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>-0.019050</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>-0.146874</td>\n",
       "      <td>-0.138703</td>\n",
       "      <td>-0.049536</td>\n",
       "      <td>-0.061698</td>\n",
       "      <td>-0.143874</td>\n",
       "      <td>-0.097804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.116207</td>\n",
       "      <td>-0.127946</td>\n",
       "      <td>-0.125014</td>\n",
       "      <td>-0.064276</td>\n",
       "      <td>-0.001586</td>\n",
       "      <td>0.048242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Sweet potatoes</th>\n",
       "      <td>-0.047050</td>\n",
       "      <td>-0.035362</td>\n",
       "      <td>-0.014972</td>\n",
       "      <td>-0.012830</td>\n",
       "      <td>-0.028174</td>\n",
       "      <td>-0.141034</td>\n",
       "      <td>-0.133188</td>\n",
       "      <td>-0.047567</td>\n",
       "      <td>-0.059245</td>\n",
       "      <td>-0.138154</td>\n",
       "      <td>-0.093916</td>\n",
       "      <td>-0.116207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.122859</td>\n",
       "      <td>-0.120044</td>\n",
       "      <td>0.041832</td>\n",
       "      <td>0.012233</td>\n",
       "      <td>0.088043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Rice, paddy</th>\n",
       "      <td>-0.032368</td>\n",
       "      <td>-0.024906</td>\n",
       "      <td>-0.027011</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>-0.004369</td>\n",
       "      <td>-0.155281</td>\n",
       "      <td>-0.146643</td>\n",
       "      <td>-0.052372</td>\n",
       "      <td>-0.065230</td>\n",
       "      <td>-0.152110</td>\n",
       "      <td>-0.103403</td>\n",
       "      <td>-0.127946</td>\n",
       "      <td>-0.122859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.132170</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>-0.001119</td>\n",
       "      <td>0.042312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Soybeans</th>\n",
       "      <td>-0.030519</td>\n",
       "      <td>-0.045891</td>\n",
       "      <td>-0.005271</td>\n",
       "      <td>-0.020590</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>-0.151723</td>\n",
       "      <td>-0.143283</td>\n",
       "      <td>-0.051172</td>\n",
       "      <td>-0.063736</td>\n",
       "      <td>-0.148625</td>\n",
       "      <td>-0.101033</td>\n",
       "      <td>-0.125014</td>\n",
       "      <td>-0.120044</td>\n",
       "      <td>-0.132170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017185</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>-0.049714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_rain_fall_mm_per_year</th>\n",
       "      <td>-0.187975</td>\n",
       "      <td>0.074217</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.174662</td>\n",
       "      <td>-0.233038</td>\n",
       "      <td>-0.053614</td>\n",
       "      <td>-0.110764</td>\n",
       "      <td>0.140193</td>\n",
       "      <td>0.124455</td>\n",
       "      <td>-0.032605</td>\n",
       "      <td>0.133368</td>\n",
       "      <td>-0.064276</td>\n",
       "      <td>0.041832</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>-0.017185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182319</td>\n",
       "      <td>0.314236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pesticides_tonnes</th>\n",
       "      <td>-0.160156</td>\n",
       "      <td>-0.277388</td>\n",
       "      <td>0.273069</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>-0.236458</td>\n",
       "      <td>-0.034586</td>\n",
       "      <td>-0.012642</td>\n",
       "      <td>-0.070127</td>\n",
       "      <td>0.107397</td>\n",
       "      <td>-0.026889</td>\n",
       "      <td>0.029863</td>\n",
       "      <td>-0.001586</td>\n",
       "      <td>0.012233</td>\n",
       "      <td>-0.001119</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>0.182319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_temp</th>\n",
       "      <td>-0.102554</td>\n",
       "      <td>-0.137627</td>\n",
       "      <td>0.171113</td>\n",
       "      <td>0.109561</td>\n",
       "      <td>-0.257576</td>\n",
       "      <td>-0.098620</td>\n",
       "      <td>-0.156473</td>\n",
       "      <td>0.085172</td>\n",
       "      <td>0.062092</td>\n",
       "      <td>-0.043180</td>\n",
       "      <td>0.163273</td>\n",
       "      <td>0.048242</td>\n",
       "      <td>0.088043</td>\n",
       "      <td>0.042312</td>\n",
       "      <td>-0.049714</td>\n",
       "      <td>0.314236</td>\n",
       "      <td>0.031550</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Area_0    Area_1    Area_2    Area_3  \\\n",
       "Area_0                         1.000000 -0.177355 -0.119036 -0.009138   \n",
       "Area_1                        -0.177355  1.000000 -0.061769  0.029130   \n",
       "Area_2                        -0.119036 -0.061769  1.000000 -0.126279   \n",
       "Area_3                        -0.009138  0.029130 -0.126279  1.000000   \n",
       "Area_4                        -0.040623  0.113405 -0.157695 -0.044654   \n",
       "Item_Potatoes                  0.052354  0.022105 -0.008270  0.024766   \n",
       "Item_Wheat                     0.071782  0.030191 -0.012391 -0.016493   \n",
       "Item_Plantains and others     -0.017358  0.070041  0.001647  0.028347   \n",
       "Item_Yams                     -0.009495 -0.024156  0.044973  0.056043   \n",
       "Item_Maize                     0.023937  0.024535 -0.006985 -0.026536   \n",
       "Item_Cassava                  -0.042775 -0.004848  0.055197  0.028323   \n",
       "Item_Sorghum                  -0.007638  0.006347  0.007334 -0.019050   \n",
       "Item_Sweet potatoes           -0.047050 -0.035362 -0.014972 -0.012830   \n",
       "Item_Rice, paddy              -0.032368 -0.024906 -0.027011  0.004689   \n",
       "Item_Soybeans                 -0.030519 -0.045891 -0.005271 -0.020590   \n",
       "average_rain_fall_mm_per_year -0.187975  0.074217  0.100981  0.174662   \n",
       "pesticides_tonnes             -0.160156 -0.277388  0.273069  0.004806   \n",
       "avg_temp                      -0.102554 -0.137627  0.171113  0.109561   \n",
       "\n",
       "                                 Area_4  Item_Potatoes  Item_Wheat  \\\n",
       "Area_0                        -0.040623       0.052354    0.071782   \n",
       "Area_1                         0.113405       0.022105    0.030191   \n",
       "Area_2                        -0.157695      -0.008270   -0.012391   \n",
       "Area_3                        -0.044654       0.024766   -0.016493   \n",
       "Area_4                         1.000000       0.010411    0.040790   \n",
       "Item_Potatoes                  0.010411       1.000000   -0.168337   \n",
       "Item_Wheat                     0.040790      -0.168337    1.000000   \n",
       "Item_Plantains and others      0.006190      -0.060119   -0.056775   \n",
       "Item_Yams                     -0.041465      -0.074880   -0.070714   \n",
       "Item_Maize                     0.022875      -0.174613   -0.164899   \n",
       "Item_Cassava                  -0.102920      -0.118700   -0.112096   \n",
       "Item_Sorghum                   0.016477      -0.146874   -0.138703   \n",
       "Item_Sweet potatoes           -0.028174      -0.141034   -0.133188   \n",
       "Item_Rice, paddy              -0.004369      -0.155281   -0.146643   \n",
       "Item_Soybeans                  0.037732      -0.151723   -0.143283   \n",
       "average_rain_fall_mm_per_year -0.233038      -0.053614   -0.110764   \n",
       "pesticides_tonnes             -0.236458      -0.034586   -0.012642   \n",
       "avg_temp                      -0.257576      -0.098620   -0.156473   \n",
       "\n",
       "                               Item_Plantains and others  Item_Yams  \\\n",
       "Area_0                                         -0.017358  -0.009495   \n",
       "Area_1                                          0.070041  -0.024156   \n",
       "Area_2                                          0.001647   0.044973   \n",
       "Area_3                                          0.028347   0.056043   \n",
       "Area_4                                          0.006190  -0.041465   \n",
       "Item_Potatoes                                  -0.060119  -0.074880   \n",
       "Item_Wheat                                     -0.056775  -0.070714   \n",
       "Item_Plantains and others                       1.000000  -0.025255   \n",
       "Item_Yams                                      -0.025255   1.000000   \n",
       "Item_Maize                                     -0.058891  -0.073351   \n",
       "Item_Cassava                                   -0.040034  -0.049863   \n",
       "Item_Sorghum                                   -0.049536  -0.061698   \n",
       "Item_Sweet potatoes                            -0.047567  -0.059245   \n",
       "Item_Rice, paddy                               -0.052372  -0.065230   \n",
       "Item_Soybeans                                  -0.051172  -0.063736   \n",
       "average_rain_fall_mm_per_year                   0.140193   0.124455   \n",
       "pesticides_tonnes                              -0.070127   0.107397   \n",
       "avg_temp                                        0.085172   0.062092   \n",
       "\n",
       "                               Item_Maize  Item_Cassava  Item_Sorghum  \\\n",
       "Area_0                           0.023937     -0.042775     -0.007638   \n",
       "Area_1                           0.024535     -0.004848      0.006347   \n",
       "Area_2                          -0.006985      0.055197      0.007334   \n",
       "Area_3                          -0.026536      0.028323     -0.019050   \n",
       "Area_4                           0.022875     -0.102920      0.016477   \n",
       "Item_Potatoes                   -0.174613     -0.118700     -0.146874   \n",
       "Item_Wheat                      -0.164899     -0.112096     -0.138703   \n",
       "Item_Plantains and others       -0.058891     -0.040034     -0.049536   \n",
       "Item_Yams                       -0.073351     -0.049863     -0.061698   \n",
       "Item_Maize                       1.000000     -0.116276     -0.143874   \n",
       "Item_Cassava                    -0.116276      1.000000     -0.097804   \n",
       "Item_Sorghum                    -0.143874     -0.097804      1.000000   \n",
       "Item_Sweet potatoes             -0.138154     -0.093916     -0.116207   \n",
       "Item_Rice, paddy                -0.152110     -0.103403     -0.127946   \n",
       "Item_Soybeans                   -0.148625     -0.101033     -0.125014   \n",
       "average_rain_fall_mm_per_year   -0.032605      0.133368     -0.064276   \n",
       "pesticides_tonnes               -0.026889      0.029863     -0.001586   \n",
       "avg_temp                        -0.043180      0.163273      0.048242   \n",
       "\n",
       "                               Item_Sweet potatoes  Item_Rice, paddy  \\\n",
       "Area_0                                   -0.047050         -0.032368   \n",
       "Area_1                                   -0.035362         -0.024906   \n",
       "Area_2                                   -0.014972         -0.027011   \n",
       "Area_3                                   -0.012830          0.004689   \n",
       "Area_4                                   -0.028174         -0.004369   \n",
       "Item_Potatoes                            -0.141034         -0.155281   \n",
       "Item_Wheat                               -0.133188         -0.146643   \n",
       "Item_Plantains and others                -0.047567         -0.052372   \n",
       "Item_Yams                                -0.059245         -0.065230   \n",
       "Item_Maize                               -0.138154         -0.152110   \n",
       "Item_Cassava                             -0.093916         -0.103403   \n",
       "Item_Sorghum                             -0.116207         -0.127946   \n",
       "Item_Sweet potatoes                       1.000000         -0.122859   \n",
       "Item_Rice, paddy                         -0.122859          1.000000   \n",
       "Item_Soybeans                            -0.120044         -0.132170   \n",
       "average_rain_fall_mm_per_year             0.041832          0.018401   \n",
       "pesticides_tonnes                         0.012233         -0.001119   \n",
       "avg_temp                                  0.088043          0.042312   \n",
       "\n",
       "                               Item_Soybeans  average_rain_fall_mm_per_year  \\\n",
       "Area_0                             -0.030519                      -0.187975   \n",
       "Area_1                             -0.045891                       0.074217   \n",
       "Area_2                             -0.005271                       0.100981   \n",
       "Area_3                             -0.020590                       0.174662   \n",
       "Area_4                              0.037732                      -0.233038   \n",
       "Item_Potatoes                      -0.151723                      -0.053614   \n",
       "Item_Wheat                         -0.143283                      -0.110764   \n",
       "Item_Plantains and others          -0.051172                       0.140193   \n",
       "Item_Yams                          -0.063736                       0.124455   \n",
       "Item_Maize                         -0.148625                      -0.032605   \n",
       "Item_Cassava                       -0.101033                       0.133368   \n",
       "Item_Sorghum                       -0.125014                      -0.064276   \n",
       "Item_Sweet potatoes                -0.120044                       0.041832   \n",
       "Item_Rice, paddy                   -0.132170                       0.018401   \n",
       "Item_Soybeans                       1.000000                      -0.017185   \n",
       "average_rain_fall_mm_per_year      -0.017185                       1.000000   \n",
       "pesticides_tonnes                   0.021860                       0.182319   \n",
       "avg_temp                           -0.049714                       0.314236   \n",
       "\n",
       "                               pesticides_tonnes  avg_temp  \n",
       "Area_0                                 -0.160156 -0.102554  \n",
       "Area_1                                 -0.277388 -0.137627  \n",
       "Area_2                                  0.273069  0.171113  \n",
       "Area_3                                  0.004806  0.109561  \n",
       "Area_4                                 -0.236458 -0.257576  \n",
       "Item_Potatoes                          -0.034586 -0.098620  \n",
       "Item_Wheat                             -0.012642 -0.156473  \n",
       "Item_Plantains and others              -0.070127  0.085172  \n",
       "Item_Yams                               0.107397  0.062092  \n",
       "Item_Maize                             -0.026889 -0.043180  \n",
       "Item_Cassava                            0.029863  0.163273  \n",
       "Item_Sorghum                           -0.001586  0.048242  \n",
       "Item_Sweet potatoes                     0.012233  0.088043  \n",
       "Item_Rice, paddy                       -0.001119  0.042312  \n",
       "Item_Soybeans                           0.021860 -0.049714  \n",
       "average_rain_fall_mm_per_year           0.182319  0.314236  \n",
       "pesticides_tonnes                       1.000000  0.031550  \n",
       "avg_temp                                0.031550  1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_x = StandardScaler()\n",
    "X_train = ss_x.fit_transform(X_train)\n",
    "X_test = ss_x.transform(X_test)\n",
    "\n",
    "ss_y = StandardScaler()\n",
    "y_train = ss_y.fit_transform(y_train)\n",
    "y_test = ss_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27158931, -0.65302538, -1.29127055, ...,  1.59081483,\n",
       "        -0.50306731,  1.07952211],\n",
       "       [-0.27158931, -0.65302538, -1.29127055, ..., -0.72453517,\n",
       "         0.06101976, -1.27084462],\n",
       "       [-0.27158931, -0.65302538, -1.29127055, ..., -0.86818827,\n",
       "        -0.21950894, -0.49425683],\n",
       "       ...,\n",
       "       [-0.27158931,  2.02437275, -1.29127055, ..., -0.64707516,\n",
       "        -0.61378113, -1.877851  ],\n",
       "       [ 3.68203006, -0.65302538,  1.25209509, ..., -1.5160356 ,\n",
       "        -0.61678012,  1.16985987],\n",
       "       [-0.27158931, -0.65302538, -0.01958773, ..., -0.09499658,\n",
       "         0.13154402,  0.7625475 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(0.9)\n",
    "\n",
    "pca_X_train = pca.fit_transform(X_train)\n",
    "pca_X_test = pca.transform(X_test)\n",
    "\n",
    "len(pca_X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28827ab4740>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1 = LinearRegression()\n",
    "reg1.fit(pca_X_train, y_train.ravel())\n",
    "reg2 = DecisionTreeRegressor()\n",
    "reg2.fit(pca_X_train, y_train.ravel())\n",
    "reg3 = RandomForestRegressor(n_estimators=100)\n",
    "reg3.fit(pca_X_train, y_train.ravel())\n",
    "reg4 = SVR(kernel = 'rbf')\n",
    "reg4.fit(pca_X_train, y_train.ravel())\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree = 4)\n",
    "X_poly = poly_reg.fit_transform(pca_X_train)\n",
    "reg5 = LinearRegression()\n",
    "reg5.fit(X_poly, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingRegressor(n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BaggingRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.BaggingRegressor.html\">?<span>Documentation for BaggingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>BaggingRegressor(n_estimators=100)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "BaggingRegressor(n_estimators=100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg6 = BaggingRegressor(n_estimators=100)\n",
    "reg6.fit(pca_X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = reg1.predict(pca_X_test).reshape(-1, 1)\n",
    "y_pred2 = reg2.predict(pca_X_test).reshape(-1, 1)\n",
    "y_pred3 = reg3.predict(pca_X_test).reshape(-1, 1)\n",
    "y_pred4 = reg4.predict(pca_X_test).reshape(-1, 1)\n",
    "y_pred5 = reg5.predict(poly_reg.transform(pca_X_test)).reshape(-1, 1)\n",
    "y_pred6 = reg6.predict(pca_X_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_unscaled = ss_y.inverse_transform(y_test)\n",
    "pred1 = ss_y.inverse_transform(y_pred1)\n",
    "pred2 = ss_y.inverse_transform(y_pred2)\n",
    "pred3 = ss_y.inverse_transform(y_pred3)\n",
    "pred4 = ss_y.inverse_transform(y_pred4)\n",
    "pred5 = ss_y.inverse_transform(y_pred5)\n",
    "pred6 = ss_y.inverse_transform(y_pred6)\n",
    "\n",
    "metrics['Linear Regression'] = {\n",
    "    'MSE': mean_squared_error(y_test_unscaled, pred1),\n",
    "    'RMSE': root_mean_squared_error(y_test_unscaled, pred1),\n",
    "    'MAE': mean_absolute_error(y_test_unscaled, pred1),\n",
    "    'R2': r2_score(y_test_unscaled, pred1)\n",
    "}\n",
    "\n",
    "metrics['Decision Tree'] = {\n",
    "    'MSE': mean_squared_error(y_test_unscaled, pred2),\n",
    "    'RMSE': root_mean_squared_error(y_test_unscaled, pred2),\n",
    "    'MAE': mean_absolute_error(y_test_unscaled, pred2),\n",
    "    'R2': r2_score(y_test_unscaled, pred2)\n",
    "}\n",
    "\n",
    "metrics['Random Forest'] = {\n",
    "    'MSE': mean_squared_error(y_test_unscaled, pred3),\n",
    "    'RMSE': root_mean_squared_error(y_test_unscaled, pred3),\n",
    "    'MAE': mean_absolute_error(y_test_unscaled, pred3),\n",
    "    'R2': r2_score(y_test_unscaled, pred3)\n",
    "}\n",
    "\n",
    "metrics['SVR'] = {\n",
    "    'MSE': mean_squared_error(y_test_unscaled, pred4),\n",
    "    'RMSE': root_mean_squared_error(y_test_unscaled, pred4),\n",
    "    'MAE': mean_absolute_error(y_test_unscaled, pred4),\n",
    "    'R2': r2_score(y_test_unscaled, pred4)\n",
    "}\n",
    "\n",
    "metrics['Polynomial Regression'] = {\n",
    "    'MSE': mean_squared_error(y_test_unscaled, pred5),\n",
    "    'RMSE': root_mean_squared_error(y_test_unscaled, pred5),\n",
    "    'MAE': mean_absolute_error(y_test_unscaled, pred5),\n",
    "    'R2': r2_score(y_test_unscaled, pred5)\n",
    "}\n",
    "\n",
    "metrics['Bagging Regressor'] = {\n",
    "    'MSE': mean_squared_error(y_test_unscaled, pred6),\n",
    "    'RMSE': root_mean_squared_error(y_test_unscaled, pred6),\n",
    "    'MAE': mean_absolute_error(y_test_unscaled, pred6),\n",
    "    'R2': r2_score(y_test_unscaled, pred6)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(len(X_train[0]),)),\n",
    "        keras.layers.Dropout(0.05),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.05),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.05),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dropout(0.05),\n",
    "        keras.layers.Dense(1, activation='linear')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,265</span> (106.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,265\u001b[0m (106.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,265</span> (106.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,265\u001b[0m (106.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='mse',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.4007 - mae: 0.4037 - mse: 0.4007 - val_loss: 0.1608 - val_mae: 0.2319 - val_mse: 0.1608\n",
      "Epoch 2/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1929 - mae: 0.2721 - mse: 0.1929 - val_loss: 0.1352 - val_mae: 0.2225 - val_mse: 0.1352\n",
      "Epoch 3/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1728 - mae: 0.2531 - mse: 0.1728 - val_loss: 0.1135 - val_mae: 0.2001 - val_mse: 0.1135\n",
      "Epoch 4/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1565 - mae: 0.2440 - mse: 0.1565 - val_loss: 0.0957 - val_mae: 0.1882 - val_mse: 0.0957\n",
      "Epoch 5/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1487 - mae: 0.2319 - mse: 0.1487 - val_loss: 0.0838 - val_mae: 0.1733 - val_mse: 0.0838\n",
      "Epoch 6/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1403 - mae: 0.2260 - mse: 0.1403 - val_loss: 0.0789 - val_mae: 0.1611 - val_mse: 0.0789\n",
      "Epoch 7/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1278 - mae: 0.2179 - mse: 0.1278 - val_loss: 0.0772 - val_mae: 0.1726 - val_mse: 0.0772\n",
      "Epoch 8/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1313 - mae: 0.2185 - mse: 0.1313 - val_loss: 0.0745 - val_mae: 0.1615 - val_mse: 0.0745\n",
      "Epoch 9/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1099 - mae: 0.2013 - mse: 0.1099 - val_loss: 0.0690 - val_mae: 0.1590 - val_mse: 0.0690\n",
      "Epoch 10/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1163 - mae: 0.2058 - mse: 0.1163 - val_loss: 0.0688 - val_mae: 0.1484 - val_mse: 0.0688\n",
      "Epoch 11/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1069 - mae: 0.1967 - mse: 0.1069 - val_loss: 0.0691 - val_mae: 0.1555 - val_mse: 0.0691\n",
      "Epoch 12/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1084 - mae: 0.1966 - mse: 0.1084 - val_loss: 0.0709 - val_mae: 0.1631 - val_mse: 0.0709\n",
      "Epoch 13/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1087 - mae: 0.1992 - mse: 0.1087 - val_loss: 0.0667 - val_mae: 0.1584 - val_mse: 0.0667\n",
      "Epoch 14/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1094 - mae: 0.1957 - mse: 0.1094 - val_loss: 0.0731 - val_mae: 0.1610 - val_mse: 0.0731\n",
      "Epoch 15/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1082 - mae: 0.1927 - mse: 0.1082 - val_loss: 0.0701 - val_mae: 0.1525 - val_mse: 0.0701\n",
      "Epoch 16/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1027 - mae: 0.1890 - mse: 0.1027 - val_loss: 0.0673 - val_mae: 0.1578 - val_mse: 0.0673\n",
      "Epoch 17/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0998 - mae: 0.1895 - mse: 0.0998 - val_loss: 0.0670 - val_mae: 0.1571 - val_mse: 0.0670\n",
      "Epoch 18/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1014 - mae: 0.1862 - mse: 0.1014 - val_loss: 0.0640 - val_mae: 0.1424 - val_mse: 0.0640\n",
      "Epoch 19/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0960 - mae: 0.1828 - mse: 0.0960 - val_loss: 0.0663 - val_mae: 0.1527 - val_mse: 0.0663\n",
      "Epoch 20/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0963 - mae: 0.1810 - mse: 0.0963 - val_loss: 0.0653 - val_mae: 0.1447 - val_mse: 0.0653\n",
      "Epoch 21/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0989 - mae: 0.1817 - mse: 0.0989 - val_loss: 0.0625 - val_mae: 0.1387 - val_mse: 0.0625\n",
      "Epoch 22/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0952 - mae: 0.1797 - mse: 0.0952 - val_loss: 0.0624 - val_mae: 0.1458 - val_mse: 0.0624\n",
      "Epoch 23/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0900 - mae: 0.1756 - mse: 0.0900 - val_loss: 0.0643 - val_mae: 0.1525 - val_mse: 0.0643\n",
      "Epoch 24/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0940 - mae: 0.1775 - mse: 0.0940 - val_loss: 0.0640 - val_mae: 0.1410 - val_mse: 0.0640\n",
      "Epoch 25/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0961 - mae: 0.1795 - mse: 0.0961 - val_loss: 0.0619 - val_mae: 0.1365 - val_mse: 0.0619\n",
      "Epoch 26/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0914 - mae: 0.1743 - mse: 0.0914 - val_loss: 0.0592 - val_mae: 0.1413 - val_mse: 0.0592\n",
      "Epoch 27/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0922 - mae: 0.1768 - mse: 0.0922 - val_loss: 0.0581 - val_mae: 0.1335 - val_mse: 0.0581\n",
      "Epoch 28/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0901 - mae: 0.1742 - mse: 0.0901 - val_loss: 0.0579 - val_mae: 0.1348 - val_mse: 0.0579\n",
      "Epoch 29/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0863 - mae: 0.1720 - mse: 0.0863 - val_loss: 0.0591 - val_mae: 0.1403 - val_mse: 0.0591\n",
      "Epoch 30/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0849 - mae: 0.1700 - mse: 0.0849 - val_loss: 0.0567 - val_mae: 0.1306 - val_mse: 0.0567\n",
      "Epoch 31/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0884 - mae: 0.1726 - mse: 0.0884 - val_loss: 0.0577 - val_mae: 0.1319 - val_mse: 0.0577\n",
      "Epoch 32/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0854 - mae: 0.1706 - mse: 0.0854 - val_loss: 0.0622 - val_mae: 0.1365 - val_mse: 0.0622\n",
      "Epoch 33/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0941 - mae: 0.1741 - mse: 0.0941 - val_loss: 0.0575 - val_mae: 0.1314 - val_mse: 0.0575\n",
      "Epoch 34/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0874 - mae: 0.1712 - mse: 0.0874 - val_loss: 0.0575 - val_mae: 0.1397 - val_mse: 0.0575\n",
      "Epoch 35/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0891 - mae: 0.1703 - mse: 0.0891 - val_loss: 0.0584 - val_mae: 0.1371 - val_mse: 0.0584\n",
      "Epoch 36/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0871 - mae: 0.1679 - mse: 0.0871 - val_loss: 0.0571 - val_mae: 0.1278 - val_mse: 0.0571\n",
      "Epoch 37/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0868 - mae: 0.1690 - mse: 0.0868 - val_loss: 0.0573 - val_mae: 0.1316 - val_mse: 0.0573\n",
      "Epoch 38/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0878 - mae: 0.1682 - mse: 0.0878 - val_loss: 0.0576 - val_mae: 0.1317 - val_mse: 0.0576\n",
      "Epoch 39/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0782 - mae: 0.1624 - mse: 0.0782 - val_loss: 0.0556 - val_mae: 0.1267 - val_mse: 0.0556\n",
      "Epoch 40/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0803 - mae: 0.1638 - mse: 0.0803 - val_loss: 0.0558 - val_mae: 0.1297 - val_mse: 0.0558\n",
      "Epoch 41/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0835 - mae: 0.1649 - mse: 0.0835 - val_loss: 0.0577 - val_mae: 0.1364 - val_mse: 0.0577\n",
      "Epoch 42/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0810 - mae: 0.1629 - mse: 0.0810 - val_loss: 0.0585 - val_mae: 0.1303 - val_mse: 0.0585\n",
      "Epoch 43/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0832 - mae: 0.1648 - mse: 0.0832 - val_loss: 0.0603 - val_mae: 0.1428 - val_mse: 0.0603\n",
      "Epoch 44/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0847 - mae: 0.1636 - mse: 0.0847 - val_loss: 0.0578 - val_mae: 0.1397 - val_mse: 0.0578\n",
      "Epoch 45/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0875 - mae: 0.1680 - mse: 0.0875 - val_loss: 0.0592 - val_mae: 0.1331 - val_mse: 0.0592\n",
      "Epoch 46/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0803 - mae: 0.1631 - mse: 0.0803 - val_loss: 0.0570 - val_mae: 0.1291 - val_mse: 0.0570\n",
      "Epoch 47/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0812 - mae: 0.1620 - mse: 0.0812 - val_loss: 0.0598 - val_mae: 0.1351 - val_mse: 0.0598\n",
      "Epoch 48/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0837 - mae: 0.1649 - mse: 0.0837 - val_loss: 0.0569 - val_mae: 0.1293 - val_mse: 0.0569\n",
      "Epoch 49/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0855 - mae: 0.1656 - mse: 0.0855 - val_loss: 0.0537 - val_mae: 0.1250 - val_mse: 0.0537\n",
      "Epoch 50/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0840 - mae: 0.1634 - mse: 0.0840 - val_loss: 0.0556 - val_mae: 0.1291 - val_mse: 0.0556\n",
      "Epoch 51/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0778 - mae: 0.1576 - mse: 0.0778 - val_loss: 0.0598 - val_mae: 0.1344 - val_mse: 0.0598\n",
      "Epoch 52/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0841 - mae: 0.1640 - mse: 0.0841 - val_loss: 0.0564 - val_mae: 0.1302 - val_mse: 0.0564\n",
      "Epoch 53/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0764 - mae: 0.1615 - mse: 0.0764 - val_loss: 0.0542 - val_mae: 0.1282 - val_mse: 0.0542\n",
      "Epoch 54/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0735 - mae: 0.1559 - mse: 0.0735 - val_loss: 0.0563 - val_mae: 0.1311 - val_mse: 0.0563\n",
      "Epoch 55/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0806 - mae: 0.1620 - mse: 0.0806 - val_loss: 0.0548 - val_mae: 0.1275 - val_mse: 0.0548\n",
      "Epoch 56/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0767 - mae: 0.1578 - mse: 0.0767 - val_loss: 0.0541 - val_mae: 0.1305 - val_mse: 0.0541\n",
      "Epoch 57/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0821 - mae: 0.1598 - mse: 0.0821 - val_loss: 0.0550 - val_mae: 0.1359 - val_mse: 0.0550\n",
      "Epoch 58/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0775 - mae: 0.1582 - mse: 0.0775 - val_loss: 0.0596 - val_mae: 0.1292 - val_mse: 0.0596\n",
      "Epoch 59/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0784 - mae: 0.1596 - mse: 0.0784 - val_loss: 0.0547 - val_mae: 0.1267 - val_mse: 0.0547\n",
      "Epoch 60/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0788 - mae: 0.1589 - mse: 0.0788 - val_loss: 0.0566 - val_mae: 0.1271 - val_mse: 0.0566\n",
      "Epoch 61/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0773 - mae: 0.1568 - mse: 0.0773 - val_loss: 0.0588 - val_mae: 0.1295 - val_mse: 0.0588\n",
      "Epoch 62/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0768 - mae: 0.1581 - mse: 0.0768 - val_loss: 0.0568 - val_mae: 0.1365 - val_mse: 0.0568\n",
      "Epoch 63/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0747 - mae: 0.1556 - mse: 0.0747 - val_loss: 0.0554 - val_mae: 0.1299 - val_mse: 0.0554\n",
      "Epoch 64/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0793 - mae: 0.1583 - mse: 0.0793 - val_loss: 0.0552 - val_mae: 0.1255 - val_mse: 0.0552\n",
      "Epoch 65/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0788 - mae: 0.1589 - mse: 0.0788 - val_loss: 0.0559 - val_mae: 0.1351 - val_mse: 0.0559\n",
      "Epoch 66/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0749 - mae: 0.1568 - mse: 0.0749 - val_loss: 0.0545 - val_mae: 0.1249 - val_mse: 0.0545\n",
      "Epoch 67/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0756 - mae: 0.1585 - mse: 0.0756 - val_loss: 0.0532 - val_mae: 0.1245 - val_mse: 0.0532\n",
      "Epoch 68/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0703 - mae: 0.1515 - mse: 0.0703 - val_loss: 0.0564 - val_mae: 0.1286 - val_mse: 0.0564\n",
      "Epoch 69/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0751 - mae: 0.1562 - mse: 0.0751 - val_loss: 0.0562 - val_mae: 0.1275 - val_mse: 0.0562\n",
      "Epoch 70/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0734 - mae: 0.1549 - mse: 0.0734 - val_loss: 0.0557 - val_mae: 0.1297 - val_mse: 0.0557\n",
      "Epoch 71/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0772 - mae: 0.1563 - mse: 0.0772 - val_loss: 0.0557 - val_mae: 0.1302 - val_mse: 0.0557\n",
      "Epoch 72/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0806 - mae: 0.1566 - mse: 0.0806 - val_loss: 0.0536 - val_mae: 0.1283 - val_mse: 0.0536\n",
      "Epoch 73/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0746 - mae: 0.1551 - mse: 0.0746 - val_loss: 0.0535 - val_mae: 0.1218 - val_mse: 0.0535\n",
      "Epoch 74/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0763 - mae: 0.1549 - mse: 0.0763 - val_loss: 0.0559 - val_mae: 0.1312 - val_mse: 0.0559\n",
      "Epoch 75/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0764 - mae: 0.1560 - mse: 0.0764 - val_loss: 0.0595 - val_mae: 0.1307 - val_mse: 0.0595\n",
      "Epoch 76/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0773 - mae: 0.1547 - mse: 0.0773 - val_loss: 0.0547 - val_mae: 0.1254 - val_mse: 0.0547\n",
      "Epoch 77/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0835 - mae: 0.1578 - mse: 0.0835 - val_loss: 0.0548 - val_mae: 0.1261 - val_mse: 0.0548\n",
      "Epoch 78/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0766 - mae: 0.1545 - mse: 0.0766 - val_loss: 0.0536 - val_mae: 0.1264 - val_mse: 0.0536\n",
      "Epoch 79/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0771 - mae: 0.1552 - mse: 0.0771 - val_loss: 0.0549 - val_mae: 0.1268 - val_mse: 0.0549\n",
      "Epoch 80/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0732 - mae: 0.1520 - mse: 0.0732 - val_loss: 0.0537 - val_mae: 0.1227 - val_mse: 0.0537\n",
      "Epoch 81/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0767 - mae: 0.1550 - mse: 0.0767 - val_loss: 0.0547 - val_mae: 0.1256 - val_mse: 0.0547\n",
      "Epoch 82/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0742 - mae: 0.1536 - mse: 0.0742 - val_loss: 0.0535 - val_mae: 0.1240 - val_mse: 0.0535\n",
      "Epoch 83/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0772 - mae: 0.1567 - mse: 0.0772 - val_loss: 0.0542 - val_mae: 0.1268 - val_mse: 0.0542\n",
      "Epoch 84/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0820 - mae: 0.1587 - mse: 0.0820 - val_loss: 0.0540 - val_mae: 0.1237 - val_mse: 0.0540\n",
      "Epoch 85/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0751 - mae: 0.1523 - mse: 0.0751 - val_loss: 0.0555 - val_mae: 0.1323 - val_mse: 0.0555\n",
      "Epoch 86/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0798 - mae: 0.1575 - mse: 0.0798 - val_loss: 0.0527 - val_mae: 0.1213 - val_mse: 0.0527\n",
      "Epoch 87/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0708 - mae: 0.1517 - mse: 0.0708 - val_loss: 0.0539 - val_mae: 0.1236 - val_mse: 0.0539\n",
      "Epoch 88/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0746 - mae: 0.1568 - mse: 0.0746 - val_loss: 0.0524 - val_mae: 0.1213 - val_mse: 0.0524\n",
      "Epoch 89/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0744 - mae: 0.1540 - mse: 0.0744 - val_loss: 0.0522 - val_mae: 0.1210 - val_mse: 0.0522\n",
      "Epoch 90/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0729 - mae: 0.1534 - mse: 0.0729 - val_loss: 0.0529 - val_mae: 0.1226 - val_mse: 0.0529\n",
      "Epoch 91/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0681 - mae: 0.1502 - mse: 0.0681 - val_loss: 0.0523 - val_mae: 0.1222 - val_mse: 0.0523\n",
      "Epoch 92/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0712 - mae: 0.1511 - mse: 0.0712 - val_loss: 0.0534 - val_mae: 0.1259 - val_mse: 0.0534\n",
      "Epoch 93/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0746 - mae: 0.1543 - mse: 0.0746 - val_loss: 0.0539 - val_mae: 0.1262 - val_mse: 0.0539\n",
      "Epoch 94/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0735 - mae: 0.1512 - mse: 0.0735 - val_loss: 0.0538 - val_mae: 0.1310 - val_mse: 0.0538\n",
      "Epoch 95/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0676 - mae: 0.1496 - mse: 0.0676 - val_loss: 0.0543 - val_mae: 0.1270 - val_mse: 0.0543\n",
      "Epoch 96/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0742 - mae: 0.1525 - mse: 0.0742 - val_loss: 0.0534 - val_mae: 0.1226 - val_mse: 0.0534\n",
      "Epoch 97/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0675 - mae: 0.1492 - mse: 0.0675 - val_loss: 0.0518 - val_mae: 0.1244 - val_mse: 0.0518\n",
      "Epoch 98/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0703 - mae: 0.1492 - mse: 0.0703 - val_loss: 0.0529 - val_mae: 0.1260 - val_mse: 0.0529\n",
      "Epoch 99/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0724 - mae: 0.1502 - mse: 0.0724 - val_loss: 0.0534 - val_mae: 0.1230 - val_mse: 0.0534\n",
      "Epoch 100/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0790 - mae: 0.1567 - mse: 0.0790 - val_loss: 0.0541 - val_mae: 0.1282 - val_mse: 0.0541\n",
      "Epoch 101/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0673 - mae: 0.1459 - mse: 0.0673 - val_loss: 0.0535 - val_mae: 0.1227 - val_mse: 0.0535\n",
      "Epoch 102/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0733 - mae: 0.1521 - mse: 0.0733 - val_loss: 0.0544 - val_mae: 0.1239 - val_mse: 0.0544\n",
      "Epoch 103/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0725 - mae: 0.1496 - mse: 0.0725 - val_loss: 0.0543 - val_mae: 0.1304 - val_mse: 0.0543\n",
      "Epoch 104/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0724 - mae: 0.1503 - mse: 0.0724 - val_loss: 0.0514 - val_mae: 0.1197 - val_mse: 0.0514\n",
      "Epoch 105/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0712 - mae: 0.1527 - mse: 0.0712 - val_loss: 0.0529 - val_mae: 0.1209 - val_mse: 0.0529\n",
      "Epoch 106/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0717 - mae: 0.1508 - mse: 0.0717 - val_loss: 0.0530 - val_mae: 0.1228 - val_mse: 0.0530\n",
      "Epoch 107/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0708 - mae: 0.1492 - mse: 0.0708 - val_loss: 0.0529 - val_mae: 0.1209 - val_mse: 0.0529\n",
      "Epoch 108/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0640 - mae: 0.1448 - mse: 0.0640 - val_loss: 0.0526 - val_mae: 0.1237 - val_mse: 0.0526\n",
      "Epoch 109/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0807 - mae: 0.1569 - mse: 0.0807 - val_loss: 0.0549 - val_mae: 0.1265 - val_mse: 0.0549\n",
      "Epoch 110/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0691 - mae: 0.1487 - mse: 0.0691 - val_loss: 0.0526 - val_mae: 0.1219 - val_mse: 0.0526\n",
      "Epoch 111/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0732 - mae: 0.1485 - mse: 0.0732 - val_loss: 0.0532 - val_mae: 0.1254 - val_mse: 0.0532\n",
      "Epoch 112/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0707 - mae: 0.1470 - mse: 0.0707 - val_loss: 0.0531 - val_mae: 0.1220 - val_mse: 0.0531\n",
      "Epoch 113/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0718 - mae: 0.1498 - mse: 0.0718 - val_loss: 0.0567 - val_mae: 0.1256 - val_mse: 0.0567\n",
      "Epoch 114/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0674 - mae: 0.1470 - mse: 0.0674 - val_loss: 0.0559 - val_mae: 0.1238 - val_mse: 0.0559\n",
      "Epoch 115/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0739 - mae: 0.1507 - mse: 0.0739 - val_loss: 0.0536 - val_mae: 0.1254 - val_mse: 0.0536\n",
      "Epoch 116/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0708 - mae: 0.1495 - mse: 0.0708 - val_loss: 0.0541 - val_mae: 0.1223 - val_mse: 0.0541\n",
      "Epoch 117/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0704 - mae: 0.1481 - mse: 0.0704 - val_loss: 0.0528 - val_mae: 0.1191 - val_mse: 0.0528\n",
      "Epoch 118/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0704 - mae: 0.1483 - mse: 0.0704 - val_loss: 0.0532 - val_mae: 0.1221 - val_mse: 0.0532\n",
      "Epoch 119/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0700 - mae: 0.1496 - mse: 0.0700 - val_loss: 0.0536 - val_mae: 0.1275 - val_mse: 0.0536\n",
      "Epoch 120/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0717 - mae: 0.1487 - mse: 0.0717 - val_loss: 0.0526 - val_mae: 0.1195 - val_mse: 0.0526\n",
      "Epoch 121/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0672 - mae: 0.1470 - mse: 0.0672 - val_loss: 0.0517 - val_mae: 0.1192 - val_mse: 0.0517\n",
      "Epoch 122/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0668 - mae: 0.1450 - mse: 0.0668 - val_loss: 0.0545 - val_mae: 0.1231 - val_mse: 0.0545\n",
      "Epoch 123/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0761 - mae: 0.1526 - mse: 0.0761 - val_loss: 0.0523 - val_mae: 0.1241 - val_mse: 0.0523\n",
      "Epoch 124/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0705 - mae: 0.1499 - mse: 0.0705 - val_loss: 0.0519 - val_mae: 0.1204 - val_mse: 0.0519\n",
      "Epoch 125/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0657 - mae: 0.1473 - mse: 0.0657 - val_loss: 0.0542 - val_mae: 0.1241 - val_mse: 0.0542\n",
      "Epoch 126/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0685 - mae: 0.1477 - mse: 0.0685 - val_loss: 0.0533 - val_mae: 0.1216 - val_mse: 0.0533\n",
      "Epoch 127/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0684 - mae: 0.1489 - mse: 0.0684 - val_loss: 0.0549 - val_mae: 0.1273 - val_mse: 0.0549\n",
      "Epoch 128/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0680 - mae: 0.1465 - mse: 0.0680 - val_loss: 0.0521 - val_mae: 0.1250 - val_mse: 0.0521\n",
      "Epoch 129/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0737 - mae: 0.1492 - mse: 0.0737 - val_loss: 0.0524 - val_mae: 0.1206 - val_mse: 0.0524\n",
      "Epoch 130/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0717 - mae: 0.1486 - mse: 0.0717 - val_loss: 0.0519 - val_mae: 0.1224 - val_mse: 0.0519\n",
      "Epoch 131/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0645 - mae: 0.1454 - mse: 0.0645 - val_loss: 0.0524 - val_mae: 0.1260 - val_mse: 0.0524\n",
      "Epoch 132/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0685 - mae: 0.1465 - mse: 0.0685 - val_loss: 0.0506 - val_mae: 0.1203 - val_mse: 0.0506\n",
      "Epoch 133/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0709 - mae: 0.1506 - mse: 0.0709 - val_loss: 0.0511 - val_mae: 0.1203 - val_mse: 0.0511\n",
      "Epoch 134/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0666 - mae: 0.1440 - mse: 0.0666 - val_loss: 0.0524 - val_mae: 0.1216 - val_mse: 0.0524\n",
      "Epoch 135/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0709 - mae: 0.1469 - mse: 0.0709 - val_loss: 0.0512 - val_mae: 0.1198 - val_mse: 0.0512\n",
      "Epoch 136/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0672 - mae: 0.1460 - mse: 0.0672 - val_loss: 0.0531 - val_mae: 0.1317 - val_mse: 0.0531\n",
      "Epoch 137/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0740 - mae: 0.1519 - mse: 0.0740 - val_loss: 0.0519 - val_mae: 0.1194 - val_mse: 0.0519\n",
      "Epoch 138/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0751 - mae: 0.1544 - mse: 0.0751 - val_loss: 0.0508 - val_mae: 0.1189 - val_mse: 0.0508\n",
      "Epoch 139/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0698 - mae: 0.1490 - mse: 0.0698 - val_loss: 0.0513 - val_mae: 0.1208 - val_mse: 0.0513\n",
      "Epoch 140/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0683 - mae: 0.1481 - mse: 0.0683 - val_loss: 0.0532 - val_mae: 0.1194 - val_mse: 0.0532\n",
      "Epoch 141/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0716 - mae: 0.1489 - mse: 0.0716 - val_loss: 0.0540 - val_mae: 0.1245 - val_mse: 0.0540\n",
      "Epoch 142/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0732 - mae: 0.1491 - mse: 0.0732 - val_loss: 0.0534 - val_mae: 0.1221 - val_mse: 0.0534\n",
      "Epoch 143/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0717 - mae: 0.1484 - mse: 0.0717 - val_loss: 0.0525 - val_mae: 0.1199 - val_mse: 0.0525\n",
      "Epoch 144/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0678 - mae: 0.1464 - mse: 0.0678 - val_loss: 0.0530 - val_mae: 0.1208 - val_mse: 0.0530\n",
      "Epoch 145/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0683 - mae: 0.1473 - mse: 0.0683 - val_loss: 0.0516 - val_mae: 0.1208 - val_mse: 0.0516\n",
      "Epoch 146/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0711 - mae: 0.1490 - mse: 0.0711 - val_loss: 0.0526 - val_mae: 0.1267 - val_mse: 0.0526\n",
      "Epoch 147/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0675 - mae: 0.1465 - mse: 0.0675 - val_loss: 0.0514 - val_mae: 0.1204 - val_mse: 0.0514\n",
      "Epoch 148/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0716 - mae: 0.1488 - mse: 0.0716 - val_loss: 0.0515 - val_mae: 0.1220 - val_mse: 0.0515\n",
      "Epoch 149/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0679 - mae: 0.1480 - mse: 0.0679 - val_loss: 0.0516 - val_mae: 0.1202 - val_mse: 0.0516\n",
      "Epoch 150/150\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0687 - mae: 0.1469 - mse: 0.0687 - val_loss: 0.0517 - val_mae: 0.1203 - val_mse: 0.0517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28827ae4770>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step\n"
     ]
    }
   ],
   "source": [
    "preds = mlp_model.predict(X_test)\n",
    "y_test_unscaled = ss_y.inverse_transform(y_test)\n",
    "preds = ss_y.inverse_transform(preds)\n",
    "\n",
    "metrics['MLP'] = {\n",
    "    'MSE': mean_squared_error(y_test_unscaled, preds),\n",
    "    'RMSE': root_mean_squared_error(y_test_unscaled, preds),\n",
    "    'MAE': mean_absolute_error(y_test_unscaled, preds),\n",
    "    'R2': r2_score(y_test_unscaled, preds)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dheoz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "\n",
    "tabnet_reg = TabNetRegressor(\n",
    "    optimizer_params=dict(lr=3e-2),\n",
    "    scheduler_params={\"step_size\": 30, \"gamma\": 0.10},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    n_d=24,\n",
    "    n_a=24,\n",
    "    n_steps=30,\n",
    "    gamma=0.10,\n",
    "    lambda_sparse=1e-5,\n",
    "    seed=766,\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 8.38907 | train_mse: 0.26736 | valid_mse: 0.28072 |  0:00:22s\n",
      "epoch 1  | loss: 0.19703 | train_mse: 0.23804 | valid_mse: 0.24747 |  0:00:48s\n",
      "epoch 2  | loss: 0.12899 | train_mse: 0.11374 | valid_mse: 0.12223 |  0:01:10s\n",
      "epoch 3  | loss: 0.0982  | train_mse: 0.07726 | valid_mse: 0.08492 |  0:01:33s\n",
      "epoch 4  | loss: 0.08838 | train_mse: 0.06838 | valid_mse: 0.07744 |  0:01:56s\n",
      "epoch 5  | loss: 0.07571 | train_mse: 0.05875 | valid_mse: 0.06636 |  0:02:18s\n",
      "epoch 6  | loss: 0.07003 | train_mse: 0.05783 | valid_mse: 0.0665  |  0:02:41s\n",
      "epoch 7  | loss: 0.0697  | train_mse: 0.05517 | valid_mse: 0.06251 |  0:03:04s\n",
      "epoch 8  | loss: 0.06637 | train_mse: 0.0591  | valid_mse: 0.06415 |  0:03:28s\n",
      "epoch 9  | loss: 0.06176 | train_mse: 0.05661 | valid_mse: 0.0658  |  0:03:50s\n",
      "epoch 10 | loss: 0.06126 | train_mse: 0.05226 | valid_mse: 0.0579  |  0:04:13s\n",
      "epoch 11 | loss: 0.0612  | train_mse: 0.05134 | valid_mse: 0.0583  |  0:04:35s\n",
      "epoch 12 | loss: 0.06054 | train_mse: 0.06084 | valid_mse: 0.06969 |  0:04:58s\n",
      "epoch 13 | loss: 0.05631 | train_mse: 0.05182 | valid_mse: 0.0608  |  0:05:20s\n",
      "epoch 14 | loss: 0.0602  | train_mse: 0.05386 | valid_mse: 0.06267 |  0:05:43s\n",
      "epoch 15 | loss: 0.05722 | train_mse: 0.05154 | valid_mse: 0.05974 |  0:06:05s\n",
      "epoch 16 | loss: 0.05581 | train_mse: 0.05238 | valid_mse: 0.06236 |  0:06:26s\n",
      "epoch 17 | loss: 0.05534 | train_mse: 0.04857 | valid_mse: 0.05555 |  0:06:48s\n",
      "epoch 18 | loss: 0.05644 | train_mse: 0.04685 | valid_mse: 0.05358 |  0:07:09s\n",
      "epoch 19 | loss: 0.05517 | train_mse: 0.04648 | valid_mse: 0.05461 |  0:07:31s\n",
      "epoch 20 | loss: 0.05534 | train_mse: 0.05135 | valid_mse: 0.05938 |  0:07:52s\n",
      "epoch 21 | loss: 0.05482 | train_mse: 0.04712 | valid_mse: 0.05569 |  0:08:13s\n",
      "epoch 22 | loss: 0.05219 | train_mse: 0.04585 | valid_mse: 0.05403 |  0:08:34s\n",
      "epoch 23 | loss: 0.05224 | train_mse: 0.04436 | valid_mse: 0.05286 |  0:08:55s\n",
      "epoch 24 | loss: 0.05285 | train_mse: 0.0508  | valid_mse: 0.05959 |  0:09:17s\n",
      "epoch 25 | loss: 0.05214 | train_mse: 0.04467 | valid_mse: 0.05246 |  0:09:39s\n",
      "epoch 26 | loss: 0.05128 | train_mse: 0.04541 | valid_mse: 0.0542  |  0:10:00s\n",
      "epoch 27 | loss: 0.05151 | train_mse: 0.05275 | valid_mse: 0.0604  |  0:10:22s\n",
      "epoch 28 | loss: 0.05251 | train_mse: 0.04602 | valid_mse: 0.05364 |  0:10:45s\n",
      "epoch 29 | loss: 0.05202 | train_mse: 0.04559 | valid_mse: 0.05208 |  0:11:06s\n",
      "epoch 30 | loss: 0.04471 | train_mse: 0.03898 | valid_mse: 0.04575 |  0:11:27s\n",
      "epoch 31 | loss: 0.04198 | train_mse: 0.03844 | valid_mse: 0.04578 |  0:11:48s\n",
      "epoch 32 | loss: 0.04134 | train_mse: 0.03799 | valid_mse: 0.04553 |  0:12:09s\n",
      "epoch 33 | loss: 0.0419  | train_mse: 0.03815 | valid_mse: 0.04561 |  0:12:30s\n",
      "epoch 34 | loss: 0.04113 | train_mse: 0.03756 | valid_mse: 0.04513 |  0:12:53s\n",
      "epoch 35 | loss: 0.04109 | train_mse: 0.03876 | valid_mse: 0.04603 |  0:13:15s\n",
      "epoch 36 | loss: 0.04135 | train_mse: 0.03762 | valid_mse: 0.04507 |  0:13:38s\n",
      "epoch 37 | loss: 0.04208 | train_mse: 0.03749 | valid_mse: 0.04501 |  0:14:00s\n",
      "epoch 38 | loss: 0.04075 | train_mse: 0.03755 | valid_mse: 0.04506 |  0:14:23s\n",
      "epoch 39 | loss: 0.04062 | train_mse: 0.03761 | valid_mse: 0.04551 |  0:14:46s\n",
      "epoch 40 | loss: 0.04059 | train_mse: 0.03775 | valid_mse: 0.0454  |  0:15:08s\n",
      "epoch 41 | loss: 0.0409  | train_mse: 0.03715 | valid_mse: 0.04487 |  0:15:31s\n",
      "epoch 42 | loss: 0.04112 | train_mse: 0.03763 | valid_mse: 0.04566 |  0:15:55s\n",
      "epoch 43 | loss: 0.04107 | train_mse: 0.03657 | valid_mse: 0.04436 |  0:16:17s\n",
      "epoch 44 | loss: 0.04081 | train_mse: 0.03709 | valid_mse: 0.04489 |  0:16:40s\n",
      "epoch 45 | loss: 0.04062 | train_mse: 0.03761 | valid_mse: 0.04543 |  0:17:02s\n",
      "epoch 46 | loss: 0.04096 | train_mse: 0.03672 | valid_mse: 0.0448  |  0:17:24s\n",
      "epoch 47 | loss: 0.04045 | train_mse: 0.03726 | valid_mse: 0.04501 |  0:17:47s\n",
      "epoch 48 | loss: 0.04051 | train_mse: 0.03687 | valid_mse: 0.0449  |  0:18:10s\n",
      "epoch 49 | loss: 0.03982 | train_mse: 0.03715 | valid_mse: 0.04485 |  0:18:32s\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 43 and best_valid_mse = 0.04436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dheoz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "tabnet_reg.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['mse'],\n",
    "    max_epochs=50,\n",
    "    patience=10,\n",
    "    batch_size=256,\n",
    "    virtual_batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tabnet_reg.predict(X_test)\n",
    "y_test_unscaled = ss_y.inverse_transform(y_test)\n",
    "preds = ss_y.inverse_transform(preds)\n",
    "\n",
    "metrics['TabNet'] = {\n",
    "    'MSE': mean_squared_error(y_test_unscaled, preds),\n",
    "    'RMSE': root_mean_squared_error(y_test_unscaled, preds),\n",
    "    'MAE': mean_absolute_error(y_test_unscaled, preds),\n",
    "    'R2': r2_score(y_test_unscaled, preds)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tabnet\n",
    "R2 = 0.9576048496756998\n",
    "MSE = 317191154.00337845\n",
    "MAE = 8549.929656124807\n",
    "RMSE = 17809.861144977476\n",
    "\n",
    "mlp\n",
    "R2 = 0.9455535352238054\n",
    "MSE = 407356427.83808315\n",
    "MAE = 10397.462190487255\n",
    "RMSE = 20183.072804656953"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import RegressionBlock, Learner, Categorify, TabularPandas\n",
    "from tsai.models.TabTransformer import TabTransformer\n",
    "from fastai.losses import MSELossFlat\n",
    "from fastai.metrics import AccumMetric\n",
    "import numpy as np\n",
    "\n",
    "SEED = 766\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_metric(preds, true):\n",
    "    preds = preds.squeeze()\n",
    "    return r2_score(true.cpu().numpy(), preds.cpu().numpy())\n",
    "\n",
    "def rmse_metric(preds, true):\n",
    "    preds = preds.squeeze()\n",
    "    return np.sqrt(mean_squared_error(true.cpu().numpy(), preds.cpu().numpy()))\n",
    "\n",
    "def mae_metric(preds, true):\n",
    "    preds = preds.squeeze()\n",
    "    return mean_absolute_error(true.cpu().numpy(), preds.cpu().numpy())\n",
    "\n",
    "# Register metrics\n",
    "r2_metric = AccumMetric(r2_score_metric, flatten=False)\n",
    "rmse_metric = AccumMetric(rmse_metric, flatten=False)\n",
    "mae_metric = AccumMetric(mae_metric, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data.csv')\n",
    "target_col = 'hg/ha_yield'\n",
    "cat_names = ['Area', 'Item']\n",
    "cont_names = ['average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp']\n",
    "\n",
    "for cat in cat_names:\n",
    "    all_categories = df[cat].astype(str).unique().tolist() + ['unknown'] # Add 'unknown' for unknown categories\n",
    "    df[cat] = pd.Categorical(df[cat], categories=all_categories)\n",
    "\n",
    "classes = {cat: df[cat].cat.categories.tolist() for cat in cat_names}\n",
    "\n",
    "train_set, valid_set = train_test_split(range(len(df)), test_size=0.2, random_state=SEED)\n",
    "splits = (list(train_set), list(valid_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>r2_score_metric</th>\n",
       "      <th>rmse_metric</th>\n",
       "      <th>mae_metric</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12992248832.000000</td>\n",
       "      <td>13557096448.000000</td>\n",
       "      <td>-0.812015</td>\n",
       "      <td>116434.953927</td>\n",
       "      <td>77944.382812</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13250401280.000000</td>\n",
       "      <td>13348774912.000000</td>\n",
       "      <td>-0.784171</td>\n",
       "      <td>115536.889624</td>\n",
       "      <td>76599.851562</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10707310592.000000</td>\n",
       "      <td>10789457920.000000</td>\n",
       "      <td>-0.442097</td>\n",
       "      <td>103872.295748</td>\n",
       "      <td>61673.046875</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4450447360.000000</td>\n",
       "      <td>3928957952.000000</td>\n",
       "      <td>0.474863</td>\n",
       "      <td>62681.404451</td>\n",
       "      <td>31334.876953</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1676207104.000000</td>\n",
       "      <td>1532703360.000000</td>\n",
       "      <td>0.795142</td>\n",
       "      <td>39149.757190</td>\n",
       "      <td>21703.683594</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>943201472.000000</td>\n",
       "      <td>807513152.000000</td>\n",
       "      <td>0.892069</td>\n",
       "      <td>28416.777016</td>\n",
       "      <td>17027.580078</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>617653184.000000</td>\n",
       "      <td>646079488.000000</td>\n",
       "      <td>0.913646</td>\n",
       "      <td>25418.091195</td>\n",
       "      <td>14826.043945</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>569560448.000000</td>\n",
       "      <td>581366080.000000</td>\n",
       "      <td>0.922296</td>\n",
       "      <td>24111.532842</td>\n",
       "      <td>14146.989258</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>533699232.000000</td>\n",
       "      <td>533432128.000000</td>\n",
       "      <td>0.928702</td>\n",
       "      <td>23096.148943</td>\n",
       "      <td>13424.875000</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>543924032.000000</td>\n",
       "      <td>535733760.000000</td>\n",
       "      <td>0.928395</td>\n",
       "      <td>23145.925948</td>\n",
       "      <td>13055.470703</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>542821312.000000</td>\n",
       "      <td>517903072.000000</td>\n",
       "      <td>0.930778</td>\n",
       "      <td>22757.483868</td>\n",
       "      <td>13444.240234</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>488079840.000000</td>\n",
       "      <td>507752416.000000</td>\n",
       "      <td>0.932135</td>\n",
       "      <td>22533.362288</td>\n",
       "      <td>13047.188477</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>486402944.000000</td>\n",
       "      <td>502366112.000000</td>\n",
       "      <td>0.932855</td>\n",
       "      <td>22413.526630</td>\n",
       "      <td>12573.369141</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>450724672.000000</td>\n",
       "      <td>477605472.000000</td>\n",
       "      <td>0.936164</td>\n",
       "      <td>21854.188798</td>\n",
       "      <td>12240.485352</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>468413632.000000</td>\n",
       "      <td>475460256.000000</td>\n",
       "      <td>0.936451</td>\n",
       "      <td>21805.051158</td>\n",
       "      <td>12228.763672</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>473104832.000000</td>\n",
       "      <td>472023840.000000</td>\n",
       "      <td>0.936910</td>\n",
       "      <td>21726.109638</td>\n",
       "      <td>12062.184570</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>430722240.000000</td>\n",
       "      <td>466121120.000000</td>\n",
       "      <td>0.937699</td>\n",
       "      <td>21589.837609</td>\n",
       "      <td>11945.632812</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>393306144.000000</td>\n",
       "      <td>466928864.000000</td>\n",
       "      <td>0.937591</td>\n",
       "      <td>21608.539793</td>\n",
       "      <td>11795.140625</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>430315488.000000</td>\n",
       "      <td>465127968.000000</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>21566.828603</td>\n",
       "      <td>11812.000977</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>451650880.000000</td>\n",
       "      <td>464370080.000000</td>\n",
       "      <td>0.937933</td>\n",
       "      <td>21549.247783</td>\n",
       "      <td>11804.132812</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "procs = [Categorify]\n",
    "config = TabularPandas(\n",
    "    df, \n",
    "    procs=procs,\n",
    "    cat_names=cat_names,\n",
    "    cont_names=cont_names,\n",
    "    y_names=target_col,\n",
    "    splits=splits,\n",
    "    y_block=RegressionBlock()\n",
    ")\n",
    "dls = config.dataloaders(bs=64, seed=SEED)\n",
    "\n",
    "model = TabTransformer(classes=classes, cont_names=cont_names, c_out=1, d_model=64)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat(), metrics=[r2_metric, rmse_metric, mae_metric])\n",
    "learn.fit_one_cycle(20, 0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['TabTransformer'] = {\n",
    "    'MSE': learn.recorder.final_record[1],\n",
    "    'RMSE': learn.recorder.final_record[3],\n",
    "    'MAE': learn.recorder.final_record[4],\n",
    "    'R2': learn.recorder.final_record[2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best one is TabNet Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2.681733e+09</td>\n",
       "      <td>51785.455596</td>\n",
       "      <td>32177.682148</td>\n",
       "      <td>0.641565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>5.160668e+08</td>\n",
       "      <td>22717.104478</td>\n",
       "      <td>8874.150027</td>\n",
       "      <td>0.931024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.568644e+08</td>\n",
       "      <td>18890.853710</td>\n",
       "      <td>7999.454127</td>\n",
       "      <td>0.952302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>9.470257e+08</td>\n",
       "      <td>30773.783118</td>\n",
       "      <td>15664.866213</td>\n",
       "      <td>0.873422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>3.672604e+08</td>\n",
       "      <td>19164.038085</td>\n",
       "      <td>9464.786474</td>\n",
       "      <td>0.950913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>3.585769e+08</td>\n",
       "      <td>18936.127676</td>\n",
       "      <td>7967.255763</td>\n",
       "      <td>0.952073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>3.595240e+08</td>\n",
       "      <td>18961.119036</td>\n",
       "      <td>9563.158206</td>\n",
       "      <td>0.951947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>3.171912e+08</td>\n",
       "      <td>17809.861145</td>\n",
       "      <td>8549.929656</td>\n",
       "      <td>0.957605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TabTransformer</td>\n",
       "      <td>4.643701e+08</td>\n",
       "      <td>21549.247783</td>\n",
       "      <td>11804.132812</td>\n",
       "      <td>0.937933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model           MSE          RMSE           MAE        R2\n",
       "0      Linear Regression  2.681733e+09  51785.455596  32177.682148  0.641565\n",
       "1          Decision Tree  5.160668e+08  22717.104478   8874.150027  0.931024\n",
       "2          Random Forest  3.568644e+08  18890.853710   7999.454127  0.952302\n",
       "3                    SVR  9.470257e+08  30773.783118  15664.866213  0.873422\n",
       "4  Polynomial Regression  3.672604e+08  19164.038085   9464.786474  0.950913\n",
       "5      Bagging Regressor  3.585769e+08  18936.127676   7967.255763  0.952073\n",
       "6                    MLP  3.595240e+08  18961.119036   9563.158206  0.951947\n",
       "7                 TabNet  3.171912e+08  17809.861145   8549.929656  0.957605\n",
       "8         TabTransformer  4.643701e+08  21549.247783  11804.132812  0.937933"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(metrics).T\n",
    "df_results = df_results.reset_index().rename(columns={'index': 'Model'})\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
