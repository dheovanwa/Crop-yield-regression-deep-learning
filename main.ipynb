{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/datasets/patelris/crop-yield-prediction-dataset?select=yield_df.csv\n",
    "\n",
    "Dataset features: \n",
    "- Categorical features: \"Area\", \"Item\", \"Year\"\n",
    "- Continuous features: \"average_rain_fall_mm_per_year\", \"pesticides_tonnes\", \"avg_temp\"\n",
    "- Target: \"hg/ha_yield\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "cat_cols = [\"Area\", \"Item\"]\n",
    "cont_cols = [\"average_rain_fall_mm_per_year\", \"pesticides_tonnes\", \"avg_temp\"]\n",
    "target_col = \"hg/ha_yield\"\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# drop columns that has no meaning\n",
    "df.drop(columns=['Unnamed: 0', 'Year'], axis='columns',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=766)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_encoder = ce.OneHotEncoder(\n",
    "    cols='Item',\n",
    "    handle_unknown='return_nan',\n",
    "    return_df=True,\n",
    "    use_cat_names=True\n",
    ")\n",
    "X_train = item_encoder.fit_transform(X_train)\n",
    "X_test = item_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_encoder = ce.BaseNEncoder(\n",
    "    cols='Area',\n",
    "    base=3,\n",
    "    handle_unknown='return_nan',\n",
    "    return_df=True,\n",
    ")\n",
    "X_train = area_encoder.fit_transform(X_train)\n",
    "X_test = area_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet Regressor Hyperpamater Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    optimizer_params = dict(lr=trial.suggest_float('lambda_sparse', low=1e-6, high=1e-1))\n",
    "    scheduler_params = {\"step_size\": trial.suggest_int('scheduler_step_size', low=3, high=40), \"gamma\": trial.suggest_float('scheduler_gamma', low=0.01, high=0.9)}\n",
    "    scheduler_fn = torch.optim.lr_scheduler.StepLR\n",
    "    optimizer_name = trial.suggest_categorical(\n",
    "        'optimizer_fn', \n",
    "        [\n",
    "            \"Adam\", \n",
    "            \"AdamW\",\n",
    "            \"Adamax\",\n",
    "            \"Adadelta\",\n",
    "            \"Adagrad\",\n",
    "            \"SGD\",\n",
    "            \"RMSprop\",\n",
    "            \"Rprop\"\n",
    "        ]\n",
    "    )\n",
    "    optimizer_fn = getattr(torch.optim, optimizer_name) \n",
    "\n",
    "    n_d = trial.suggest_int('n_d', low=1, high=32)\n",
    "    n_a = trial.suggest_int('n_a', low=1, high=32)\n",
    "    n_steps = trial.suggest_int('n_steps', low=3, high=40)\n",
    "    gamma = trial.suggest_float('gamma', low=0.01, high=0.9)\n",
    "    lambda_sparse = trial.suggest_float('lambda_sparse', low=1e-6, high=1e-1)\n",
    "    verbose = 1\n",
    "    device_name = 'cuda'\n",
    "\n",
    "\n",
    "    regressor = TabNetRegressor(\n",
    "        optimizer_params=optimizer_params,\n",
    "        scheduler_params=scheduler_params,\n",
    "        scheduler_fn=scheduler_fn,\n",
    "        optimizer_fn=optimizer_fn,\n",
    "        n_d=n_d,\n",
    "        n_a=n_a,\n",
    "        n_steps=n_steps,\n",
    "        gamma=gamma,\n",
    "        lambda_sparse=lambda_sparse,\n",
    "        verbose=verbose,\n",
    "        device_name=device_name,\n",
    "    )\n",
    "    regressor.fit(X_train=X_train, y_train=y_train,\n",
    "                eval_set=[(X_test, y_test)],\n",
    "                patience=15,\n",
    "                max_epochs=100,\n",
    "                batch_size=trial.suggest_int('batch_size', low=256, high=1024, step=256),\n",
    "                eval_metric=['mse'])\n",
    "    return r2_score(y_test, regressor.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import logging, sys\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name='TabNet Hyperparameter Optimization',\n",
    "    sampler=optuna.samplers.RandomSampler(),\n",
    "    storage='sqlite:///tabnet.db',\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_objective(trial):\n",
    "\n",
    "    optimizer_params = dict(lr=trial.suggest_float('lambda_sparse', low=1e-6, high=1e-1))\n",
    "    scheduler_params = {\"step_size\": trial.suggest_int('scheduler_step_size', low=3, high=40), \"gamma\": trial.suggest_float('scheduler_gamma', low=0.01, high=0.9)}\n",
    "    scheduler_fn = torch.optim.lr_scheduler.StepLR\n",
    "    optimizer_name = trial.suggest_categorical(\n",
    "        'optimizer_fn', \n",
    "        [\n",
    "            \"Adam\", \n",
    "            \"AdamW\",\n",
    "            \"Adamax\",\n",
    "            \"Adadelta\",\n",
    "            \"Adagrad\",\n",
    "            \"SGD\",\n",
    "            \"RMSprop\",\n",
    "            \"Rprop\"\n",
    "        ]\n",
    "    )\n",
    "    optimizer_fn = getattr(torch.optim, optimizer_name) \n",
    "\n",
    "    n_d = trial.suggest_int('n_d', low=1, high=32)\n",
    "    n_a = trial.suggest_int('n_a', low=1, high=32)\n",
    "    n_steps = trial.suggest_int('n_steps', low=3, high=40)\n",
    "    gamma = trial.suggest_float('gamma', low=0.01, high=0.9)\n",
    "    lambda_sparse = trial.suggest_float('lambda_sparse', low=1e-6, high=1e-1)\n",
    "    verbose = 1\n",
    "    device_name = 'cuda'\n",
    "\n",
    "\n",
    "    regressor = TabNetRegressor(\n",
    "        optimizer_params=optimizer_params,\n",
    "        scheduler_params=scheduler_params,\n",
    "        scheduler_fn=scheduler_fn,\n",
    "        optimizer_fn=optimizer_fn,\n",
    "        n_d=n_d,\n",
    "        n_a=n_a,\n",
    "        n_steps=n_steps,\n",
    "        gamma=gamma,\n",
    "        lambda_sparse=lambda_sparse,\n",
    "        verbose=verbose,\n",
    "        device_name=device_name,\n",
    "    )\n",
    "    regressor.fit(X_train=X_train, y_train=y_train,\n",
    "                eval_set=[(X_test, y_test)],\n",
    "                patience=15,\n",
    "                max_epochs=100,\n",
    "                batch_size=trial.suggest_int('batch_size', low=256, high=1024, step=256),\n",
    "                eval_metric=['mse'])\n",
    "\n",
    "    r2 = r2_score(y_test, regressor.predict(X_test))\n",
    "    mse = mean_squared_error(y_test, regressor.predict(X_test))\n",
    "    rmse = root_mean_squared_error(y_test, regressor.predict(X_test))\n",
    "    mae = mean_absolute_error(y_test, regressor.predict(X_test))\n",
    "\n",
    "    return r2, mse, rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "detailed_objective(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt = optuna.visualization.plot_optimization_history(study)\n",
    "plt.update_layout(\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    title_font_size=36,\n",
    "    legend_font_size=24,\n",
    "    font_size=18,\n",
    "    font_family='Times New Roman'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt_parallel = optuna.visualization.plot_parallel_coordinate(study, params=['optimizer_fn', 'scheduler_step_size', 'lambda_sparse'])\n",
    "plt_parallel.update_layout(\n",
    "    margin=dict(b=150),\n",
    "    width=1100,\n",
    "    height=750,\n",
    "    title_font_size=36,\n",
    "    legend_font_size=24,\n",
    "    font_size=24,\n",
    "    font_family='Times New Roman',\n",
    "    title='Notable Parameter Parallel Coordinate'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt_contour = optuna.visualization.plot_contour(study, params=['optimizer_fn', 'scheduler_step_size', 'lambda_sparse'])\n",
    "plt_contour.update_layout(\n",
    "    width=2000,\n",
    "    height=2000,\n",
    "    title_font_size=36,\n",
    "    legend_font_size=24,\n",
    "    font_size=18,\n",
    "    font_family='Times New Roman'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt_contour_optim_sched = optuna.visualization.plot_contour(study, params=['optimizer_fn', 'scheduler_step_size'])\n",
    "plt_contour_optim_sched.update_layout(\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    title_font_size=36,\n",
    "    legend_font_size=24,\n",
    "    font_size=22,\n",
    "    font_family='Times New Roman',\n",
    "    title='Relationship between Optimizer Function and Scheduler Step Size'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Optimizer Function and Lambda Sparse\", \"Scheduler Step Size and Lambda Sparse\")\n",
    ")\n",
    "\n",
    "fig_contour_optim = optuna.visualization.plot_contour(study, params=['optimizer_fn', 'lambda_sparse'])\n",
    "fig_contour_sched = optuna.visualization.plot_contour(study, params=['scheduler_step_size', 'lambda_sparse'])\n",
    "\n",
    "for trace in fig_contour_optim.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "for trace in fig_contour_sched.data:\n",
    "    fig.add_trace(trace, row=2, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1500,\n",
    "    height=1200,\n",
    "    title='Relationship between Lambda Sparse and Other Notable Hyperparameters',\n",
    "    title_font_size=46,\n",
    "    legend_font_size=24,\n",
    "    font=dict(\n",
    "        size=32,\n",
    "        family='Times New Roman'\n",
    "    )\n",
    ")\n",
    "\n",
    "for annotation in fig['layout']['annotations']:\n",
    "    annotation['font'] = dict(size=32)\n",
    "\n",
    "fig.update_xaxes(title_text=\"lambda_sparse\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"optimizer_fn\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"lambda_sparse\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"scheduler_step_size\", row=2, col=1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt_importance = optuna.visualization.plot_param_importances(study)\n",
    "plt_importance.update_layout(\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    title_font_size=36,\n",
    "    font_size=24,\n",
    "    font_family='Times New Roman'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt_rank = optuna.visualization.plot_rank(study, para)\n",
    "plt_rank.update_layout(\n",
    "    width=3000,\n",
    "    height=3000,\n",
    "    title_font_size=36,\n",
    "    font_size=24,\n",
    "    font_family='Times New Roman'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "optuna.visualization.plot_timeline(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "optuna.visualization.matplotlib.plot_edf(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
